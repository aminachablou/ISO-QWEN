# ğŸ“š ISO AI Navigator - AAAHF

**SystÃ¨me RAG intelligent pour la navigation et la conformitÃ© ISO**

Assistant IA basÃ© sur LLaMA 3.2 3B pour rÃ©pondre aux questions sur les normes ISO avec citations prÃ©cises des sources.

---

## ğŸ¯ FonctionnalitÃ©s

- âœ… **Extraction multi-format** : PDF, Word (.docx), Excel (.xlsx)
- âœ… **RAG Pipeline complet** : Embeddings BAAI + FAISS + LLaMA 3.2 3B
- âœ… **API REST** : FastAPI avec documentation Swagger
- âœ… **Interface React** : UI moderne et responsive
- âœ… **Citations de sources** : Chaque rÃ©ponse inclut les sections ISO rÃ©fÃ©rencÃ©es
- âœ… **OptimisÃ© CPU** : Fonctionne sans GPU (8GB RAM minimum)

---

## ğŸš€ Installation rapide

### PrÃ©requis
- Python 3.10+
- Node.js 16+
- 8GB RAM minimum
- Connexion internet (pour tÃ©lÃ©charger les modÃ¨les)

### Installation

```bash
# Cloner le repo
git clone https://github.com/AsamaeS/ISO_ai_AAAHF.git
cd ISO_ai_AAAHF

# Option 1 : Installation automatique (Windows)
.\install.bat

# Option 2 : Installation manuelle
cd ml_core
pip install -r requirements.txt
pip install python-docx openpyxl xlrd

cd ../iso-doc-navigator-main
npm install
echo VITE_ML_API_URL=http://localhost:8000 > .env.local
```

---

## ğŸ“„ PrÃ©parer vos documents

1. Placez vos PDFs ISO dans `ml_core/data/pdfs/`
2. Traitez les documents :

```bash
cd ml_core
python -m ml_core.ingest.batch_processor ./data/pdfs ./data/chunks ./data/index
```

â±ï¸ Temps : 3-5 minutes pour ~10 documents

---

## ğŸ® Lancement

### Backend (API ML)

```bash
cd ml_core
python -m uvicorn ml_core.api.api:app --reload --host 0.0.0.0 --port 8000
```

ğŸ•’ **Premier lancement** : 10-15 min (tÃ©lÃ©charge LLaMA 3.2 3B ~3GB)  
ğŸ•’ **Lancements suivants** : 30 secondes

### Frontend (Interface React)

```bash
cd iso-doc-navigator-main
npm run dev
```

---

## ğŸŒ AccÃ¨s

- **Interface utilisateur** : http://localhost:5173
- **API Documentation** : http://localhost:8000/docs
- **Backend API** : http://localhost:8000

---

## ğŸ“š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Documents  â”‚â”€â”€â”€â”€â–¶â”‚  Ingestion   â”‚â”€â”€â”€â”€â–¶â”‚  Embeddings â”‚
â”‚  ISO (PDF)  â”‚     â”‚   Pipeline   â”‚     â”‚  (BAAI/bge) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    LLaMA     â”‚â—€â”€â”€â”€â”€â”‚    FAISS    â”‚
                    â”‚  3.2 3B 4bit â”‚     â”‚    Index    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FastAPI    â”‚
                    â”‚  REST API    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  React UI    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technologies

### Backend ML
- **LLM** : LLaMA 3.2 3B Instruct (4-bit quantized)
- **Embeddings** : BAAI/bge-small-en-v1.5 (384 dim)
- **Vector DB** : FAISS (Facebook AI Similarity Search)
- **API** : FastAPI + Uvicorn
- **OCR** : Tesseract + PaddleOCR

### Frontend
- **Framework** : React 18 + Vite
- **UI** : TailwindCSS + shadcn/ui
- **State** : React Query (@tanstack/react-query)
- **Router** : React Router v6

---

## ğŸ“– Documentation

- **[QUICK_START.md](QUICK_START.md)** - Guide de dÃ©marrage en 3 Ã©tapes
- **[LANCEMENT.md](LANCEMENT.md)** - Instructions dÃ©taillÃ©es de lancement
- **[DEPENDANCES.md](DEPENDANCES.md)** - Informations sur les modÃ¨les ML
- **[TEST_GUIDE.md](ml_core/TEST_GUIDE.md)** - Guide de test complet
- **[INTEGRATION.md](INTEGRATION.md)** - IntÃ©gration Frontend â†”ï¸ Backend

---

## ğŸ“ Projet universitaire

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'un cours de Machine learning.

**Objectifs pÃ©dagogiques accomplis :**
- âœ… Pipeline ETL complet (PDF â†’ Chunks â†’ Embeddings)
- âœ… IntÃ©gration de modÃ¨les ML (LLaMA, BAAI)
- âœ… Optimisation pour contraintes matÃ©rielles (8GB RAM, CPU-only)
- âœ… DÃ©ploiement d'API REST
- âœ… Containerisation Docker
- âœ… Tests unitaires et d'intÃ©gration

---

## âš™ï¸ Configuration

Ã‰ditez `ml_core/config/settings.yaml` pour personnaliser :

```yaml
# ModÃ¨le LLM
llm:
  model_name: "llama-3.2-3b"  # ou llama-3.1-8b
  quantize: true              # REQUIS pour 8GB RAM
  temperature: 0.7

# Embeddings
embeddings:
  model_name: "BAAI/bge-small-en-v1.5"
  device: "cpu"

# Chunking
chunking:
  target_tokens: 400
  overlap_tokens: 50
```

---

## ğŸ³ DÃ©ploiement Docker

```bash
# Construire et lancer
docker-compose up -d

# AccÃ©der
# Frontend: http://localhost:5173
# Backend: http://localhost:8000
```

---

## ğŸ§ª Tests

```bash
cd ml_core
pytest tests/ -v
```

---

## ğŸ“Š Performance

**Configuration testÃ©e :** Intel i5, 8GB RAM, CPU uniquement

| OpÃ©ration | Temps |
|-----------|-------|
| Ingestion PDF (50 pages) | ~30 secondes |
| GÃ©nÃ©ration embeddings (100 chunks) | ~2 secondes |
| Recherche FAISS | <10 ms |
| RÃ©ponse RAG complÃ¨te | 10-20 secondes |

---

## âš ï¸ Notes importantes

### ModÃ¨les ML
Les modÃ¨les ne sont **PAS inclus** dans le repo (trop gros). Ils sont tÃ©lÃ©chargÃ©s automatiquement au premier lancement :
- LLaMA 3.2 3B : ~3 GB
- BAAI embeddings : ~130 MB

**Stockage :** `C:\Users\[USER]\.cache\huggingface\`

### DonnÃ©es
Les documents ISO et les index FAISS ne sont **PAS inclus** dans le repo. Vous devez :
1. Ajouter vos propres PDFs ISO dans `ml_core/data/pdfs/`
2. ExÃ©cuter le batch processor pour crÃ©er l'index

---

## ğŸ¤ Contribution

Projet acadÃ©mique - suggestions bienvenues !

---

## ğŸ“ Licence

Projet universitaire - Usage Ã©ducatif

---

## ğŸ‘¥ Auteurs
Asmae 
Amina
Anas
Hafsa
Fatem Zahra
**Ã‰quipe AAAHF**  
Projet ML

---

## ğŸ”— Liens utiles

- [LLaMA 3.2](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
- [BAAI/bge](https://huggingface.co/BAAI/bge-small-en-v1.5)
- [FAISS](https://github.com/facebookresearch/faiss)
- [FastAPI](https://fastapi.tiangolo.com/)

---

**Built with â¤ï¸ for ISO Compliance**
