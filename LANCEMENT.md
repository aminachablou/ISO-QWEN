# ğŸš€ GUIDE DE LANCEMENT - Chatbot ISO Navigator

## âœ… Avant de commencer

VÃ©rifiez que vous avez :
- [ ] Python 3.10+ installÃ©
- [ ] Node.js installÃ©
- [ ] Les fichiers ISO dans `ml_core/data/pdfs/`

---

## ğŸ¯ Ã‰TAPE 1 : PrÃ©parer les donnÃ©es (Ã€ FAIRE UNE SEULE FOIS)

### 1.1 Installer les dÃ©pendances Python

Ouvrez un terminal PowerShell et exÃ©cutez :

```powershell
cd d:\iso-doc-navigator-main\ml_core
pip install -r requirements.txt
pip install python-docx openpyxl xlrd
```

â±ï¸ **Temps estimÃ© :** 5 minutes

### 1.2 Traiter vos documents

```powershell
cd d:\iso-doc-navigator-main
python -m ml_core.ingest.batch_processor ./ml_core/data/pdfs ./ml_core/data/chunks ./ml_core/data/index
```

â±ï¸ **Temps estimÃ© :** 3-5 minutes

**Vous devriez voir :**
```
Found 12 documents to process
Processing: ISO_9001_V_2015_Fr.pdf
âœ“ Created 150 chunks
...
âœ“ Building FAISS index...
âœ“ Index saved to ./ml_core/data/index
```

### 1.3 VÃ©rifier que tout est prÃªt

```powershell
# VÃ©rifier les chunks
dir ml_core\data\chunks\all_documents_chunks.json

# VÃ©rifier l'index FAISS
dir ml_core\data\index\faiss_index.bin
```

âœ… Si ces fichiers existent â†’ Passez Ã  l'Ã©tape 2 !

---

## ğŸ¯ Ã‰TAPE 2 : Lancer le Backend (API ML)

Ouvrez un **NOUVEAU terminal PowerShell** :

```powershell
cd d:\iso-doc-navigator-main\ml_core
uvicorn ml_core.api.api:app --reload --host 0.0.0.0 --port 8000
```

**Vous devriez voir :**
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Application startup complete.
```

â±ï¸ **Premier lancement :** 10-15 minutes (tÃ©lÃ©chargement LLaMA 3.2 3B)  
â±ï¸ **Lancements suivants :** 30 secondes

### Tester l'API

Ouvrez votre navigateur : **http://localhost:8000/docs**

Vous devriez voir la documentation Swagger avec les endpoints :
- `POST /ask` - Poser une question
- `POST /ingest` - IngÃ©rer un document
- `GET /info` - Infos systÃ¨me

âœ… **Laissez ce terminal OUVERT** - Le backend doit rester actif !

---

## ğŸ¯ Ã‰TAPE 3 : Lancer le Frontend (Interface React)

Ouvrez un **DEUXIÃˆME terminal PowerShell** :

```powershell
cd d:\iso-doc-navigator-main\iso-doc-navigator-main
npm install
```

â±ï¸ **Temps estimÃ© :** 2-3 minutes (premiÃ¨re fois uniquement)

Ensuite, crÃ©ez le fichier de configuration :

```powershell
# CrÃ©er .env.local
echo "VITE_ML_API_URL=http://localhost:8000" > .env.local
```

Puis lancez le frontend :

```powershell
npm run dev
```

**Vous devriez voir :**
```
VITE v5.x.x  ready in 500 ms
âœ  Local:   http://localhost:5173/
```

âœ… **Laissez ce terminal OUVERT aussi !**

---

## ğŸ¯ Ã‰TAPE 4 : Utiliser le Chatbot

Ouvrez votre navigateur : **http://localhost:5173**

Vous devriez voir votre interface !

### IntÃ©grer le chatbot dans votre interface

Si votre interface React n'a pas encore le composant chatbot, utilisez les hooks que j'ai crÃ©Ã©s :

```typescript
import { useAskQuestion } from '@/hooks/useMLCore';

function ChatbotComponent() {
  const { mutate: askQuestion, data, isPending } = useAskQuestion();
  
  const handleSubmit = (question: string) => {
    askQuestion({ 
      query: question,
      top_k: 5,
      temperature: 0.7
    });
  };
  
  return (
    <div>
      {isPending && <p>Chargement...</p>}
      {data && (
        <>
          <p><strong>RÃ©ponse:</strong> {data.answer}</p>
          <div>
            <strong>Sources:</strong>
            {data.sources.map(s => (
              <div key={s.chunk_id}>
                {s.document} - {s.section} (p.{s.page})
              </div>
            ))}
          </div>
        </>
      )}
    </div>
  );
}
```

---

## ğŸ§ª TESTER avec l'API directement

Si vous voulez tester sans l'interface, utilisez curl ou PowerShell :

```powershell
# PowerShell
Invoke-RestMethod -Uri "http://localhost:8000/ask" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"query": "Qu''est-ce que l''ISO 9001?", "top_k": 3}'
```

Ou via le navigateur : http://localhost:8000/docs â†’ Testez `/ask`

---

## ğŸ“‹ RÃ‰SUMÃ‰ - Ce qui doit tourner

Vous devez avoir **2 terminaux ouverts** :

| Terminal | Commande | URL |
|----------|----------|-----|
| **Terminal 1** | `uvicorn ml_core.api.api:app --reload` | http://localhost:8000 |
| **Terminal 2** | `npm run dev` | http://localhost:5173 |

---

## ğŸ”„ WORKFLOW COMPLET

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vous posez une  â”‚
â”‚ question dans   â”‚
â”‚ l'interface     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend React  â”‚ Port 5173
â”‚ (localhost)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP POST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend FastAPI â”‚ Port 8000
â”‚ ml_core/api     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embedder     â”‚ â†’ Vectorise la question
â”‚ 2. FAISS Search â”‚ â†’ Trouve docs pertinents
â”‚ 3. LLaMA        â”‚ â†’ GÃ©nÃ¨re la rÃ©ponse
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RÃ©ponse +       â”‚
â”‚ Sources citÃ©es  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ COMMANDES RAPIDES

### Lancer tout d'un coup (Windows)

CrÃ©ez un fichier `start.bat` Ã  la racine :

```batch
@echo off
start "Backend ML" cmd /k "cd ml_core && uvicorn ml_core.api.api:app --reload"
timeout /t 5
start "Frontend React" cmd /k "cd iso-doc-navigator-main && npm run dev"
echo.
echo Chatbot dÃ©marrÃ© !
echo Backend: http://localhost:8000
echo Frontend: http://localhost:5173
```

Double-cliquez sur `start.bat` â†’ Tout dÃ©marre !

### ArrÃªter tout

- `Ctrl+C` dans chaque terminal
- Ou fermez les fenÃªtres

---

## ğŸ› PROBLÃˆMES COURANTS

### "Module not found: ml_core"
â†’ Vous n'Ãªtes pas dans le bon dossier  
â†’ Solution: `cd d:\iso-doc-navigator-main`

### "Port 8000 already in use"
â†’ Le backend tourne dÃ©jÃ   
â†’ Solution: Trouvez et fermez l'ancien processus

### "Cannot connect to API"
â†’ Le backend n'est pas dÃ©marrÃ©  
â†’ Solution: Lancez le terminal 1 (API) en premier

### "Out of memory"
â†’ Fermez les applications inutiles  
â†’ Le modÃ¨le LLaMA 4-bit nÃ©cessite ~4-6 GB RAM

### Questions sans rÃ©ponses
â†’ L'index n'a pas Ã©tÃ© crÃ©Ã©  
â†’ Relancez l'Ã©tape 1.2 (batch_processor)

---

## âœ… CHECKLIST DE DÃ‰MARRAGE

- [ ] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [ ] Documents traitÃ©s (fichier `all_documents_chunks.json` existe)
- [ ] Index FAISS crÃ©Ã© (fichier `faiss_index.bin` existe)
- [ ] Terminal 1 : Backend lancÃ© (http://localhost:8000/docs fonctionne)
- [ ] Terminal 2 : Frontend lancÃ© (http://localhost:5173 fonctionne)
- [ ] Fichier `.env.local` crÃ©Ã© avec `VITE_ML_API_URL=http://localhost:8000`

---

## ğŸ¯ PROCHAINES Ã‰TAPES

1. âœ… Lancez le systÃ¨me (Ã©tapes 2 et 3)
2. ğŸ“ Testez avec des questions simples
3. ğŸ¨ Personnalisez l'interface React si besoin
4. ğŸš€ DÃ©ployez sur un serveur (optionnel)

**Besoin d'aide ?** Consultez `TEST_GUIDE.md` pour plus de dÃ©tails !
